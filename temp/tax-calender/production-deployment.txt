# docker-compose.yml - Complete production stack
version: '3.8'

services:
  # Main Next.js application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@db:5432/uae_tax_calendar
      - REDIS_URL=redis://redis:6379
      - SOCKET_SERVER_URL=http://socket-server:4000
      - SOCKET_SECRET=${SOCKET_SECRET}
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS=${SMTP_PASS}
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - NEXTAUTH_URL=${NEXTAUTH_URL}
    ports:
      - "3000:3000"
    depends_on:
      - db
      - redis
    restart: unless-stopped
    volumes:
      - ./uploads:/app/uploads

  # Socket.IO server for real-time features
  socket-server:
    build:
      context: ./server
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
      - SOCKET_PORT=4000
      - SOCKET_SECRET=${SOCKET_SECRET}
      - REDIS_URL=redis://redis:6379
      - PG_CONNECTION=postgresql://postgres:${POSTGRES_PASSWORD}@db:5432/uae_tax_calendar
    ports:
      - "4000:4000"
    depends_on:
      - db
      - redis
    restart: unless-stopped

  # Background workers
  workers:
    build:
      context: .
      dockerfile: Dockerfile.workers
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@db:5432/uae_tax_calendar
      - REDIS_URL=redis://redis:6379
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS=${SMTP_PASS}
    depends_on:
      - db
      - redis
    restart: unless-stopped

  # PostgreSQL database
  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=uae_tax_calendar
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./migrations:/docker-entrypoint-initdb.d
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and Socket.IO adapter
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
      - socket-server
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:

---

# nginx.conf - Production Nginx configuration
events {
    worker_connections 1024;
}

http {
    upstream app {
        server app:3000;
    }

    upstream socket_server {
        server socket-server:4000;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

    server {
        listen 80;
        server_name your-domain.com www.your-domain.com;
        
        # Redirect HTTP to HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name your-domain.com www.your-domain.com;

        # SSL Configuration
        ssl_certificate /etc/nginx/ssl/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        
        # Security Headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self' wss: ws:;" always;

        # Gzip Compression
        gzip on;
        gzip_vary on;
        gzip_min_length 1024;
        gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;

        # Main application
        location / {
            proxy_pass http://app;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_read_timeout 300s;
            proxy_connect_timeout 75s;
        }

        # Socket.IO server
        location /socket.io/ {
            proxy_pass http://socket_server;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "Upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # API rate limiting
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Login rate limiting
        location /api/auth/ {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Static file caching
        location /_next/static/ {
            proxy_pass http://app;
            proxy_cache_valid 200 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}

---

# Dockerfile - Main application
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:18-alpine AS runtime
WORKDIR /app

# Create non-root user
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# Copy built application
COPY --from=build /app/public ./public
COPY --from=build --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=build --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000
ENV PORT 3000
ENV NODE_ENV production

CMD ["node", "server.js"]

---

# Dockerfile.workers - Background workers
FROM node:18-alpine
WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY workers/ ./workers/
COPY lib/ ./lib/
COPY tsconfig.json ./

RUN addgroup -g 1001 -S nodejs
RUN adduser -S worker -u 1001

USER worker

CMD ["node", "workers/index.js"]

---

# server/Dockerfile - Socket server
FROM node:18-alpine
WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY server/socket-server.js ./
COPY server/ecosystem.config.js ./

RUN addgroup -g 1001 -S nodejs
RUN adduser -S socket -u 1001

USER socket

EXPOSE 4000

CMD ["node", "socket-server.js"]

---

# .env.example - Environment variables template
# Database
DATABASE_URL=postgresql://username:password@localhost:5432/uae_tax_calendar
POSTGRES_PASSWORD=your_postgres_password

# Redis
REDIS_URL=redis://localhost:6379

# Socket.IO
SOCKET_SECRET=your_super_secret_socket_key
SOCKET_SERVER_URL=http://localhost:4000

# Email (SMTP)
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=your_email@example.com
SMTP_PASS=your_email_password
SMTP_FROM=UAE Tax Calendar <noreply@yourdomain.com>

# NextAuth.js
NEXTAUTH_SECRET=your_nextauth_secret_key
NEXTAUTH_URL=https://yourdomain.com

# Application
NEXT_PUBLIC_APP_URL=https://yourdomain.com
NEXT_PUBLIC_SOCKET_SERVER_URL=https://yourdomain.com

# Optional: Blockchain integration
BLOCKCHAIN_PROVIDER_URL=
BLOCKCHAIN_PRIVATE_KEY=

# Optional: External APIs
UAE_TAX_API_KEY=
GOOGLE_CALENDAR_API_KEY=

---

# package.json - Updated with all dependencies
{
  "name": "uae-tax-calendar",
  "version": "2.0.0",
  "description": "Professional UAE Tax Compliance Calendar with Team Collaboration",
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "migrate": "node scripts/migrate.js",
    "migrate:create": "node scripts/create-migration.js",
    "workers": "node workers/index.js",
    "socket-server": "node server/socket-server.js",
    "test": "jest",
    "test:watch": "jest --watch",
    "type-check": "tsc --noEmit"
  },
  "dependencies": {
    "next": "^14.0.0",
    "react": "^18.0.0",
    "react-dom": "^18.0.0",
    "typescript": "^5.0.0",
    "@types/node": "^20.0.0",
    "@types/react": "^18.0.0",
    "@types/react-dom": "^18.0.0",
    "pg": "^8.11.0",
    "@types/pg": "^8.10.0",
    "redis": "^4.6.0",
    "ioredis": "^5.3.0",
    "socket.io": "^4.7.0",
    "socket.io-client": "^4.7.0",
    "@socket.io/redis-adapter": "^8.2.0",
    "nodemailer": "^6.9.0",
    "@types/nodemailer": "^6.4.0",
    "next-auth": "^4.24.0",
    "bcryptjs": "^2.4.0",
    "@types/bcryptjs": "^2.4.0",
    "jsonwebtoken": "^9.0.0",
    "@types/jsonwebtoken": "^9.0.0",
    "zod": "^3.22.0",
    "date-fns": "^2.30.0",
    "lucide-react": "^0.263.1",
    "tailwindcss": "^3.3.0",
    "autoprefixer": "^10.4.0",
    "postcss": "^8.4.0",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.0.0",
    "tailwind-merge": "^1.14.0"
  },
  "devDependencies": {
    "eslint": "^8.0.0",
    "eslint-config-next": "^14.0.0",
    "@typescript-eslint/eslint-plugin": "^6.0.0",
    "@typescript-eslint/parser": "^6.0.0",
    "jest": "^29.0.0",
    "@testing-library/react": "^13.0.0",
    "@testing-library/jest-dom": "^6.0.0",
    "prettier": "^3.0.0",
    "@types/jest": "^29.0.0"
  },
  "keywords": [
    "UAE",
    "tax",
    "compliance",
    "calendar",
    "VAT",
    "corporate-tax",
    "excise-tax",
    "team-collaboration",
    "real-time",
    "notifications"
  ],
  "engines": {
    "node": ">=18.0.0"
  },
  "license": "MIT"
}

---

# scripts/migrate.js - Database migration runner
const { Client } = require('pg');
const fs = require('fs');
const path = require('path');

async function runMigrations() {
  const client = new Client({
    connectionString: process.env.DATABASE_URL
  });

  try {
    await client.connect();
    console.log('Connected to database');

    // Create migrations table if it doesn't exist
    await client.query(`
      CREATE TABLE IF NOT EXISTS migrations (
        id SERIAL PRIMARY KEY,
        filename VARCHAR(255) UNIQUE NOT NULL,
        executed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
      )
    `);

    // Get list of executed migrations
    const executed = await client.query('SELECT filename FROM migrations');
    const executedMigrations = new Set(executed.rows.map(row => row.filename));

    // Read migration files
    const migrationsDir = path.join(__dirname, '../migrations');
    const migrationFiles = fs.readdirSync(migrationsDir)
      .filter(file => file.endsWith('.sql'))
      .sort();

    console.log(`Found ${migrationFiles.length} migration files`);

    for (const file of migrationFiles) {
      if (executedMigrations.has(file)) {
        console.log(`Skipping already executed migration: ${file}`);
        continue;
      }

      console.log(`Executing migration: ${file}`);
      const migrationPath = path.join(migrationsDir, file);
      const migrationSQL = fs.readFileSync(migrationPath, 'utf8');

      await client.query('BEGIN');
      try {
        await client.query(migrationSQL);
        await client.query('INSERT INTO migrations (filename) VALUES ($1)', [file]);
        await client.query('COMMIT');
        console.log(`Successfully executed: ${file}`);
      } catch (error) {
        await client.query('ROLLBACK');
        throw new Error(`Failed to execute migration ${file}: ${error.message}`);
      }
    }

    console.log('All migrations completed successfully');
  } catch (error) {
    console.error('Migration error:', error);
    process.exit(1);
  } finally {
    await client.end();
  }
}

if (require.main === module) {
  runMigrations();
}

module.exports = { runMigrations };

---

# scripts/create-migration.js - Migration file generator
const fs = require('fs');
const path = require('path');

function createMigration(name) {
  if (!name) {
    console.error('Please provide a migration name');
    console.error('Usage: npm run migrate:create <migration_name>');
    process.exit(1);
  }

  const timestamp = new Date().toISOString().replace(/[-:T]/g, '').split('.')[0];
  const filename = `${timestamp}_${name.toLowerCase().replace(/\s+/g, '_')}.sql`;
  const filepath = path.join(__dirname, '../migrations', filename);

  const template = `-- Migration: ${name}
-- Created: ${new Date().toISOString()}
-- Description: Add your migration description here

-- Add your SQL statements here
-- Example:
-- CREATE TABLE example_table (
--   id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
--   name VARCHAR(255) NOT NULL,
--   created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
-- );
`;

  // Ensure migrations directory exists
  const migrationsDir = path.dirname(filepath);
  if (!fs.existsSync(migrationsDir)) {
    fs.mkdirSync(migrationsDir, { recursive: true });
  }

  fs.writeFileSync(filepath, template);
  console.log(`Created migration file: ${filename}`);
}

const migrationName = process.argv[2];
createMigration(migrationName);

---

# workers/index.js - Main worker process coordinator
const { notificationWorker, reminderScheduler } = require('./notification-worker');
const { ingestionWorker } = require('./ingestion-worker');

class WorkerManager {
  constructor() {
    this.workers = [];
    this.isShuttingDown = false;
  }

  async start() {
    console.log('Starting UAE Tax Calendar workers...');

    try {
      // Start notification worker
      await notificationWorker.start();
      this.workers.push(notificationWorker);

      // Start reminder scheduler
      await reminderScheduler.start();
      this.workers.push(reminderScheduler);

      // Start data ingestion worker
      await ingestionWorker.start();
      this.workers.push(ingestionWorker);

      console.log(`Successfully started ${this.workers.length} workers`);

      // Setup graceful shutdown
      this.setupGracefulShutdown();

    } catch (error) {
      console.error('Failed to start workers:', error);
      process.exit(1);
    }
  }

  setupGracefulShutdown() {
    const shutdown = async (signal) => {
      if (this.isShuttingDown) return;
      this.isShuttingDown = true;

      console.log(`Received ${signal}. Shutting down workers gracefully...`);

      const shutdownPromises = this.workers.map(worker => {
        return new Promise((resolve) => {
          try {
            worker.stop();
            resolve();
          } catch (error) {
            console.error('Error stopping worker:', error);
            resolve();
          }
        });
      });

      await Promise.all(shutdownPromises);
      console.log('All workers stopped. Goodbye!');
      process.exit(0);
    };

    process.on('SIGINT', () => shutdown('SIGINT'));
    process.on('SIGTERM', () => shutdown('SIGTERM'));

    // Handle uncaught exceptions
    process.on('uncaughtException', (error) => {
      console.error('Uncaught Exception:', error);
      shutdown('UNCAUGHT_EXCEPTION');
    });

    process.on('unhandledRejection', (reason, promise) => {
      console.error('Unhandled Rejection at:', promise, 'reason:', reason);
      shutdown('UNHANDLED_REJECTION');
    });
  }
}

if (require.main === module) {
  const manager = new WorkerManager();
  manager.start();
}

---

# workers/ingestion-worker.js - UAE tax data ingestion worker
const { query } = require('../lib/db');
const { sendNotification } = require('../lib/notifications');

class IngestionWorker {
  constructor() {
    this.isRunning = false;
    this.intervalId = null;
  }

  async start() {
    if (this.isRunning) return;
    
    this.isRunning = true;
    console.log('Starting UAE tax data ingestion worker...');
    
    // Run ingestion daily at 2 AM
    const now = new Date();
    const tomorrow2AM = new Date(now);
    tomorrow2AM.setDate(tomorrow2AM.getDate() + 1);
    tomorrow2AM.setHours(2, 0, 0, 0);
    
    const msUntil2AM = tomorrow2AM.getTime() - now.getTime();
    
    setTimeout(() => {
      this.ingestTaxData();
      // Then run every 24 hours
      this.intervalId = setInterval(() => {
        this.ingestTaxData();
      }, 24 * 60 * 60 * 1000);
    }, msUntil2AM);

    // Initial run for development
    if (process.env.NODE_ENV !== 'production') {
      await this.ingestTaxData();
    }
  }

  stop() {
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
    this.isRunning = false;
    console.log('UAE tax data ingestion worker stopped');
  }

  async ingestTaxData() {
    console.log('Starting UAE tax data ingestion...');
    
    try {
      // Ingest different types of tax data
      await this.ingestVATDeadlines();
      await this.ingestCorporateTaxDeadlines();
      await this.ingestExciseTaxDeadlines();
      await this.ingestTaxRateChanges();
      
      console.log('Tax data ingestion completed successfully');
    } catch (error) {
      console.error('Error during tax data ingestion:', error);
      
      // Notify administrators of ingestion failure
      try {
        const admins = await query(`
          SELECT u.id FROM users u 
          JOIN user_roles ur ON u.id = ur.user_id 
          WHERE ur.role = 'admin'
        `);
        
        for (const admin of admins.rows) {
          await sendNotification({
            type: 'system_alert',
            userId: admin.id,
            title: 'Tax Data Ingestion Failed',
            message: `Automated tax data ingestion failed: ${error.message}`,
            metadata: { error: error.message, timestamp: new Date().toISOString() }
          });
        }
      } catch (notifyError) {
        console.error('Failed to notify admins of ingestion failure:', notifyError);
      }
    }
  }

  async ingestVATDeadlines() {
    console.log('Ingesting VAT deadlines...');
    
    // Generate standard VAT filing deadlines
    const currentYear = new Date().getFullYear();
    const nextYear = currentYear + 1;
    
    const vatDeadlines = [];
    
    // Monthly VAT returns (28th of each month)
    for (let year of [currentYear, nextYear]) {
      for (let month = 1; month <= 12; month++) {
        const deadline = new Date(year, month, 28); // 28th of next month
        if (deadline > new Date()) { // Only future deadlines
          vatDeadlines.push({
            title: `VAT Return Filing - ${new Date(year, month - 1).toLocaleString('default', { month: 'long', year: 'numeric' })}`,
            description: `Monthly VAT return filing deadline for ${new Date(year, month - 1).toLocaleString('default', { month: 'long', year: 'numeric' })}`,
            start_date: deadline.toISOString(),
            event_type: 'vat',
            priority: 'high',
            reminder_settings: { days: [7, 3, 1] }
          });
        }
      }
    }

    await this.insertEvents(vatDeadlines, 'VAT');
  }

  async ingestCorporateTaxDeadlines() {
    console.log('Ingesting Corporate Tax deadlines...');
    
    const currentYear = new Date().getFullYear();
    const corporateDeadlines = [
      {
        title: 'Corporate Tax Return Filing',
        description: 'Annual Corporate Tax return filing deadline',
        start_date: new Date(currentYear + 1, 8, 30).toISOString(), // September 30th
        event_type: 'corporate',
        priority: 'critical',
        reminder_settings: { days: [30, 14, 7, 3, 1] }
      },
      {
        title: 'Corporate Tax Payment',
        description: 'Annual Corporate Tax payment deadline',
        start_date: new Date(currentYear + 1, 8, 30).toISOString(), // September 30th
        event_type: 'corporate',
        priority: 'critical',
        reminder_settings: { days: [30, 14, 7, 3, 1] }
      }
    ];

    await this.insertEvents(corporateDeadlines, 'Corporate Tax');
  }

  async ingestExciseTaxDeadlines() {
    console.log('Ingesting Excise Tax deadlines...');
    
    const currentYear = new Date().getFullYear();
    const nextYear = currentYear + 1;
    
    const exciseDeadlines = [];
    
    // Monthly excise tax returns (15th of each month)
    for (let year of [currentYear, nextYear]) {
      for (let month = 1; month <= 12; month++) {
        const deadline = new Date(year, month, 15); // 15th of next month
        if (deadline > new Date()) {
          exciseDeadlines.push({
            title: `Excise Tax Return - ${new Date(year, month - 1).toLocaleString('default', { month: 'long', year: 'numeric' })}`,
            description: `Monthly Excise Tax return filing deadline for ${new Date(year, month - 1).toLocaleString('default', { month: 'long', year: 'numeric' })}`,
            start_date: deadline.toISOString(),
            event_type: 'excise',
            priority: 'medium',
            reminder_settings: { days: [7, 3, 1] }
          });
        }
      }
    }

    await this.insertEvents(exciseDeadlines, 'Excise Tax');
  }

  async ingestTaxRateChanges() {
    console.log('Checking for tax rate changes...');
    
    // In a real implementation, this would check official UAE tax authority APIs
    // For now, we'll create placeholder events for known upcoming changes
    
    const rateChangeEvents = [
      {
        title: 'Review VAT Rate Changes',
        description: 'Annual review of VAT rates and regulations - check for any updates from UAE Federal Tax Authority',
        start_date: new Date(new Date().getFullYear() + 1, 0, 1).toISOString(), // January 1st
        event_type: 'vat',
        priority: 'medium',
        reminder_settings: { days: [30, 7] }
      }
    ];

    await this.insertEvents(rateChangeEvents, 'Tax Rate Updates');
  }

  async insertEvents(events, category) {
    let insertedCount = 0;
    let updatedCount = 0;

    for (const eventData of events) {
      try {
        // Check if event already exists
        const existing = await query(`
          SELECT id FROM calendar_events 
          WHERE title = $1 AND start_date::date = $2::date
        `, [eventData.title, eventData.start_date]);

        if (existing.rows.length > 0) {
          // Update existing event
          await query(`
            UPDATE calendar_events 
            SET description = $1, event_type = $2, priority = $3, 
                reminder_settings = $4, updated_at = now()
            WHERE id = $5
          `, [
            eventData.description,
            eventData.event_type,
            eventData.priority,
            JSON.stringify(eventData.reminder_settings),
            existing.rows[0].id
          ]);
          updatedCount++;
        } else {
          // Insert new event
          await query(`
            INSERT INTO calendar_events 
            (title, description, start_date, end_date, event_type, priority, 
             reminder_settings, published, created_by, tags) 
            VALUES ($1, $2, $3, $3, $4, $5, $6, true, null, $7)
          `, [
            eventData.title,
            eventData.description,
            eventData.start_date,
            eventData.event_type,
            eventData.priority,
            JSON.stringify(eventData.reminder_settings),
            JSON.stringify(['system-generated', 'official'])
          ]);
          insertedCount++;
        }
      } catch (error) {
        console.error(`Error inserting/updating event "${eventData.title}":`, error);
      }
    }

    console.log(`${category}: ${insertedCount} new events inserted, ${updatedCount} events updated`);
  }
}

module.exports = { ingestionWorker: new IngestionWorker() };

---

# .github/workflows/deploy.yml - CI/CD Pipeline
name: Deploy UAE Tax Calendar

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run type checking
        run: npm run type-check
      
      - name: Run linting
        run: npm run lint
      
      - name: Run tests
        run: npm test
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4
      
      - name: Login to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push main app
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
      
      - name: Build and push socket server
        uses: docker/build-push-action@v5
        with:
          context: ./server
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-socket:latest
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-socket:${{ github.sha }}
      
      - name: Build and push workers
        uses: docker/build-push-action@v5
        with:
          context: .
          file: Dockerfile.workers
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-workers:latest
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-workers:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to production
        run: |
          echo "Deployment would happen here"
          echo "This could use kubectl, docker-compose, or your preferred deployment method"
          # Example with docker-compose on a remote server:
          # scp docker-compose.yml user@server:/path/to/app/
          # ssh user@server 'cd /path/to/app && docker-compose pull && docker-compose up -d'

---

# Health Check and Monitoring Configuration

# monitoring/prometheus.yml - Prometheus configuration
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'uae-tax-calendar-app'
    static_configs:
      - targets: ['app:3000']
    metrics_path: '/api/metrics'
    scrape_interval: 30s

  - job_name: 'uae-tax-calendar-socket'
    static_configs:
      - targets: ['socket-server:4000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

---

# monitoring/alert_rules.yml - Prometheus alerts
groups:
  - name: uae-tax-calendar-alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High error rate detected
          description: "Error rate is {{ $value }} errors per second"

      - alert: DatabaseDown
        expr: up{job="postgres-exporter"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: Database is down
          description: "PostgreSQL database is not responding"

      - alert: RedisDown
        expr: up{job="redis-exporter"} == 0
        for: 30s
        labels:
          severity: warning
        annotations:
          summary: Redis is down
          description: "Redis cache is not responding"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High memory usage
          description: "Memory usage is above 80%"